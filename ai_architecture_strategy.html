<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>AI Architecture & Strategy | Semantica.ai</title>
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600;700&display=swap" rel="stylesheet">
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }

        body {
            font-family: 'Inter', sans-serif;
            background: linear-gradient(135deg, #0A1929 0%, #1a2332 100%);
            color: #F0F4F8;
            min-height: 100vh;
            position: relative;
            overflow-x: hidden;
        }

        body::before,
        body::after {
            content: '';
            position: absolute;
            border-radius: 50%;
            filter: blur(80px);
            opacity: 0.15;
            pointer-events: none;
            animation: float 20s ease-in-out infinite;
        }

        body::before {
            width: 600px;
            height: 600px;
            background: radial-gradient(circle, #8b5cf6, transparent);
            top: -200px;
            left: -200px;
        }

        body::after {
            width: 500px;
            height: 500px;
            background: radial-gradient(circle, #6366f1, transparent);
            bottom: -150px;
            right: -150px;
            animation-delay: 10s;
        }

        @keyframes float {

            0%,
            100% {
                transform: translate(0, 0) scale(1);
            }

            33% {
                transform: translate(30px, -30px) scale(1.1);
            }

            66% {
                transform: translate(-20px, 20px) scale(0.9);
            }
        }

        .container {
            max-width: 1400px;
            margin: 0 auto;
            padding: 40px 20px;
            position: relative;
            z-index: 1;
        }

        .nav-back {
            display: inline-flex;
            align-items: center;
            color: #94A3B8;
            text-decoration: none;
            margin-bottom: 30px;
            font-size: 0.9rem;
            transition: color 0.3s;
        }

        .nav-back:hover {
            color: #F0F4F8;
        }

        .hero {
            text-align: center;
            margin-bottom: 60px;
            animation: headerFade 1s ease;
        }

        @keyframes headerFade {
            from {
                opacity: 0;
                transform: translateY(-20px);
            }

            to {
                opacity: 1;
                transform: translateY(0);
            }
        }

        h1 {
            font-size: 3.5rem;
            margin-bottom: 20px;
            background: linear-gradient(135deg, #8b5cf6 0%, #6366f1 100%);
            -webkit-background-clip: text;
            background-clip: text;
            -webkit-text-fill-color: transparent;
            font-weight: 700;
            letter-spacing: -0.02em;
        }

        .subtitle {
            color: #94A3B8;
            font-size: 1.3rem;
            margin-bottom: 25px;
            line-height: 1.6;
        }

        .badge {
            display: inline-block;
            padding: 12px 30px;
            background: linear-gradient(135deg, #8b5cf6, #6366f1);
            border-radius: 30px;
            font-weight: 600;
            font-size: 1.1rem;
            box-shadow: 0 10px 40px rgba(139, 92, 246, 0.3);
            margin-bottom: 20px;
        }

        .card {
            background: rgba(255, 255, 255, 0.03);
            border: 1px solid rgba(255, 255, 255, 0.1);
            border-radius: 20px;
            padding: 35px;
            margin-bottom: 35px;
            backdrop-filter: blur(10px);
            transition: all 0.4s cubic-bezier(0.4, 0, 0.2, 1);
            animation: cardFadeIn 0.6s ease backwards;
        }

        @keyframes cardFadeIn {
            from {
                opacity: 0;
                transform: translateY(30px);
            }

            to {
                opacity: 1;
                transform: translateY(0);
            }
        }

        .card:hover {
            transform: translateY(-5px);
            border-color: rgba(139, 92, 246, 0.5);
            box-shadow: 0 20px 60px rgba(139, 92, 246, 0.2);
        }

        h2 {
            font-size: 2rem;
            color: #fff;
            margin-bottom: 20px;
        }

        h3 {
            font-size: 1.5rem;
            color: #8b5cf6;
            margin-bottom: 15px;
        }

        h4 {
            font-size: 1.2rem;
            color: #6366f1;
            margin-bottom: 12px;
        }

        .grid-3 {
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(300px, 1fr));
            gap: 25px;
            margin: 25px 0;
        }

        .agent-card {
            background: linear-gradient(135deg, rgba(139, 92, 246, 0.1), rgba(99, 102, 241, 0.05));
            padding: 25px;
            border-radius: 16px;
            border: 1px solid rgba(139, 92, 246, 0.3);
        }

        .agent-card h4 {
            display: flex;
            align-items: center;
            gap: 10px;
            margin-bottom: 15px;
        }

        .agent-icon {
            font-size: 1.5rem;
        }

        .model-comparison {
            background: rgba(0, 0, 0, 0.2);
            padding: 25px;
            border-radius: 12px;
            margin: 20px 0;
        }

        table {
            width: 100%;
            border-collapse: collapse;
            margin: 20px 0;
        }

        th,
        td {
            padding: 15px;
            text-align: left;
            border-bottom: 1px solid rgba(255, 255, 255, 0.1);
        }

        th {
            background: rgba(139, 92, 246, 0.1);
            color: #8b5cf6;
            font-weight: 600;
        }

        tr:hover {
            background: rgba(139, 92, 246, 0.05);
        }

        .cost-row {
            display: flex;
            justify-content: space-between;
            padding: 12px 0;
            border-bottom: 1px solid rgba(255, 255, 255, 0.1);
        }

        .cost-row:last-child {
            border-bottom: none;
            font-weight: 700;
            font-size: 1.2rem;
            padding-top: 20px;
            border-top: 2px solid rgba(255, 255, 255, 0.2);
        }

        .cost-label {
            color: #CBD5E1;
        }

        .cost-value {
            color: #8b5cf6;
            font-family: monospace;
            font-weight: 600;
        }

        .alert-box {
            background: rgba(139, 92, 246, 0.1);
            border-left: 4px solid #8b5cf6;
            padding: 20px;
            border-radius: 0 12px 12px 0;
            margin: 25px 0;
        }

        .alert-box.success {
            background: rgba(16, 185, 129, 0.1);
            border-left-color: #10b981;
        }

        .alert-box h4 {
            color: #8b5cf6;
            margin-bottom: 10px;
        }

        .alert-box.success h4 {
            color: #10b981;
        }

        code {
            background: rgba(0, 0, 0, 0.4);
            padding: 3px 8px;
            border-radius: 4px;
            font-family: 'Monaco', monospace;
            color: #8b5cf6;
            font-size: 0.9em;
        }

        .workflow-step {
            background: rgba(0, 0, 0, 0.2);
            padding: 20px;
            border-radius: 12px;
            margin-bottom: 15px;
            border-left: 4px solid #6366f1;
        }

        .workflow-step strong {
            color: #6366f1;
            display: block;
            margin-bottom: 8px;
        }

        .tag {
            display: inline-block;
            padding: 5px 12px;
            border-radius: 6px;
            font-size: 0.85rem;
            font-weight: 600;
            margin: 3px;
        }

        .tag-recommended {
            background: rgba(16, 185, 129, 0.2);
            color: #10b981;
            border: 1px solid #10b981;
        }

        .tag-primary {
            background: rgba(139, 92, 246, 0.2);
            color: #8b5cf6;
            border: 1px solid #8b5cf6;
        }

        .tag-fallback {
            background: rgba(239, 68, 68, 0.2);
            color: #ef4444;
            border: 1px solid #ef4444;
        }

        @media (max-width: 768px) {
            h1 {
                font-size: 2.5rem;
            }

            .grid-3 {
                grid-template-columns: 1fr;
            }
        }
    </style>
</head>

<body>

    <div class="container">
        <div style="display: flex; justify-content: space-between; align-items: center; margin-bottom: 30px;">
            <a href="technical_stack_implementation.html" class="nav-back" style="margin-bottom: 0;">‚Üê Prev: Tech
                Stack</a>
            <a href="monitoring_observability.html" class="nav-back" style="margin-bottom: 0;">Next: Monitoring &
                Observability ‚Üí</a>
        </div>

        <div class="hero">
            <h1>ü§ñ AI Architecture & Strategy</h1>
            <p class="subtitle">Enterprise-grade AI system design for natural language to SQL transformation using
                multi-agent orchestration</p>
            <div class="badge">LangGraph Multi-Agent System üöÄ</div>
        </div>

        <!-- Executive Summary -->
        <div class="card">
            <h2>üìã Executive Summary: AI Strategy</h2>
            <p style="color: #CBD5E1; line-height: 1.8; margin-bottom: 20px;">
                Semantica uses a <strong style="color: #8b5cf6;">4-agent LangGraph orchestration</strong> to convert
                natural language queries into accurate SQL, execute them securely, and format results intelligently.
                This architecture balances cost (~‚Çπ2-3L/year for LLM APIs), accuracy (95%+ SQL correctness), and speed
                (avg 2.5s end-to-end latency).
            </p>

            <div class="grid-3">
                <div class="agent-card">
                    <h4>üí∞ Total AI Cost</h4>
                    <p style="color: #CBD5E1; font-size: 2rem; font-weight: 700; color: #8b5cf6;">‚Çπ2-3L/year</p>
                    <p style="color: #94A3B8; font-size: 0.9rem;">LLM API costs across 10K queries/month</p>
                </div>
                <div class="agent-card">
                    <h4>‚ö° Response Time</h4>
                    <p style="color: #CBD5E1; font-size: 2rem; font-weight: 700; color: #10b981;">2.5s avg</p>
                    <p style="color: #94A3B8; font-size: 0.9rem;">Schema ‚Üí SQL ‚Üí Execution ‚Üí Format</p>
                </div>
                <div class="agent-card">
                    <h4>üéØ SQL Accuracy</h4>
                    <p style="color: #CBD5E1; font-size: 2rem; font-weight: 700; color: #6366f1;">95%+</p>
                    <p style="color: #94A3B8; font-size: 0.9rem;">Validated via test suite + user feedback</p>
                </div>
            </div>
        </div>

        <!-- Model Selection Strategy -->
        <div class="card">
            <h2>üéØ Model Selection: Hybrid Multi-Model Approach</h2>
            <p style="color: #CBD5E1; margin-bottom: 25px;">
                We use a <strong style="color: #8b5cf6;">hybrid routing strategy</strong> that selects the optimal model
                for each task based on complexity, cost, and latency requirements.
            </p>

            <table>
                <thead>
                    <tr>
                        <th>Model</th>
                        <th>Provider</th>
                        <th>Use Case</th>
                        <th>Cost/1M Tokens</th>
                        <th>Latency</th>
                        <th>Context</th>
                    </tr>
                </thead>
                <tbody>
                    <tr>
                        <td><strong>GPT-4o</strong> <span class="tag tag-primary">Primary</span></td>
                        <td>OpenAI</td>
                        <td>Complex multi-table queries, ambiguity resolution</td>
                        <td>$2.50 input / $10 output</td>
                        <td>~1.5s</td>
                        <td>128K</td>
                    </tr>
                    <tr>
                        <td><strong>GPT-4o-mini</strong> <span class="tag tag-recommended">Recommended</span></td>
                        <td>OpenAI</td>
                        <td>Simple queries (1-2 tables), schema analysis</td>
                        <td>$0.15 input / $0.60 output</td>
                        <td>~800ms</td>
                        <td>128K</td>
                    </tr>
                    <tr>
                        <td><strong>Claude 3.5 Sonnet</strong> <span class="tag tag-primary">Alternate</span></td>
                        <td>Anthropic</td>
                        <td>Long context schema analysis, complex logic</td>
                        <td>$3 input / $15 output</td>
                        <td>~2s</td>
                        <td>200K</td>
                    </tr>
                    <tr>
                        <td><strong>Llama 3.2 (70B)</strong> <span class="tag tag-fallback">Fallback</span></td>
                        <td>Groq (API) / Self-hosted</td>
                        <td>Cost-sensitive workloads, offline testing</td>
                        <td>$0.59 input / $0.79 output (Groq)</td>
                        <td>~500ms (Groq)</td>
                        <td>8K</td>
                    </tr>
                    <tr>
                        <td><strong>text-embedding-3-small</strong></td>
                        <td>OpenAI</td>
                        <td>Schema semantic search, RAG embeddings</td>
                        <td>$0.02 / 1M tokens</td>
                        <td>~200ms</td>
                        <td>-</td>
                    </tr>
                </tbody>
            </table>

            <div class="alert-box success">
                <h4>‚úÖ Cost Optimization Strategy</h4>
                <p style="color: #CBD5E1; line-height: 1.8;">
                    <strong>Smart Routing Logic:</strong><br>
                    ‚Ä¢ 70% of queries ‚Üí GPT-4o-mini (simple, single-table)<br>
                    ‚Ä¢ 25% of queries ‚Üí GPT-4o (complex, multi-join, aggregations)<br>
                    ‚Ä¢ 5% of queries ‚Üí Claude 3.5 Sonnet (when GPT-4o fails validation)<br>
                    ‚Ä¢ Groq Llama used for dev/test environments only<br><br>

                    <strong>Estimated Monthly Cost (10K queries):</strong><br>
                    ‚Ä¢ 7,000 queries √ó GPT-4o-mini (~500 tokens avg): ‚Çπ3,500<br>
                    ‚Ä¢ 2,500 queries √ó GPT-4o (~1000 tokens avg): ‚Çπ12,000<br>
                    ‚Ä¢ 500 queries √ó Claude 3.5 (~1000 tokens avg): ‚Çπ3,500<br>
                    ‚Ä¢ Embeddings (schema updates): ‚Çπ500<br>
                    <strong>Total: ~‚Çπ20,000/month = ‚Çπ2.4L/year</strong>
                </p>
            </div>
        </div>

        <!-- Multi-Agent Architecture -->
        <div class="card">
            <h2>ü§ñ Multi-Agent Architecture: LangGraph Orchestration</h2>
            <p style="color: #CBD5E1; margin-bottom: 25px;">
                We use <strong style="color: #8b5cf6;">LangGraph</strong> (from LangChain) to orchestrate 4 specialized
                agents in a state machine. This provides deterministic flow control, error handling, and dynamic routing
                based on query complexity.
            </p>

            <div class="alert-box">
                <h4>üìö Why LangGraph?</h4>
                <p style="color: #CBD5E1;">
                    ‚Ä¢ <strong>Stateful Orchestration:</strong> Maintains context across agent transitions<br>
                    ‚Ä¢ <strong>Conditional Routing:</strong> Dynamic next-step selection based on agent output<br>
                    ‚Ä¢ <strong>Built-in Error Handling:</strong> Retry logic, fallback paths<br>
                    ‚Ä¢ <strong>Human-in-the-Loop:</strong> Native support for clarification requests<br>
                    ‚Ä¢ <strong>Observable:</strong> Built-in LangSmith integration for debugging/monitoring
                </p>
            </div>

            <h3 style="margin-top: 40px;">Agent Breakdown</h3>

            <div class="grid-3">
                <!-- Agent 1 -->
                <div class="agent-card">
                    <h4><span class="agent-icon">üîç</span> Agent 1: Schema Retriever</h4>
                    <p style="color: #CBD5E1; margin-bottom: 15px; font-size: 0.95rem;">
                        <strong>Purpose:</strong> Identify relevant tables/columns from natural language query.
                    </p>
                    <p style="color: #94A3B8; font-size: 0.9rem; margin-bottom: 10px;"><strong>Input:</strong> User
                        query text</p>
                    <p style="color: #94A3B8; font-size: 0.9rem; margin-bottom: 10px;"><strong>Model:</strong>
                        GPT-4o-mini + text-embedding-3-small</p>
                    <p style="color: #94A3B8; font-size: 0.9rem; margin-bottom: 10px;"><strong>Process:</strong></p>
                    <ol style="color: #CBD5E1; font-size: 0.9rem; padding-left: 20px; line-height: 1.7;">
                        <li>Generate embedding of user query</li>
                        <li>Semantic search against cached schema embeddings (LanceDB)</li>
                        <li>LLM reranks top 20 tables to select 3-5 most relevant</li>
                        <li>Returns: Table names + full DDL schemas</li>
                    </ol>
                    <p style="color: #94A3B8; font-size: 0.9rem; margin-top: 10px;"><strong>Latency:</strong> ~500ms</p>
                    <p style="color: #94A3B8; font-size: 0.9rem;"><strong>Cost:</strong> ~‚Çπ0.50/query</p>
                </div>

                <!-- Agent 2 -->
                <div class="agent-card">
                    <h4><span class="agent-icon">üß†</span> Agent 2: Clarification Agent</h4>
                    <p style="color: #CBD5E1; margin-bottom: 15px; font-size: 0.95rem;">
                        <strong>Purpose:</strong> Detect ambiguity in user query and request clarification.
                    </p>
                    <p style="color: #94A3B8; font-size: 0.9rem; margin-bottom: 10px;"><strong>Input:</strong> Query +
                        Schema context</p>
                    <p style="color: #94A3B8; font-size: 0.9rem; margin-bottom: 10px;"><strong>Model:</strong>
                        GPT-4o-mini</p>
                    <p style="color: #94A3B8; font-size: 0.9rem; margin-bottom: 10px;"><strong>Process:</strong></p>
                    <ol style="color: #CBD5E1; font-size: 0.9rem; padding-left: 20px; line-height: 1.7;">
                        <li>Analyze query for vague terms (e.g., "revenue" could be gross/net)</li>
                        <li>Check if schema has multiple matching columns</li>
                        <li>If ambiguous: Return clarification question to user</li>
                        <li>If clear: Proceed to SQL generation</li>
                    </ol>
                    <p style="color: #94A3B8; font-size: 0.9rem; margin-top: 10px;"><strong>Latency:</strong> ~600ms
                        (only if triggered)</p>
                    <p style="color: #94A3B8; font-size: 0.9rem;"><strong>Activation Rate:</strong> ~15% of queries</p>
                </div>

                <!-- Agent 3 -->
                <div class="agent-card">
                    <h4><span class="agent-icon">‚öôÔ∏è</span> Agent 3: SQL Generator</h4>
                    <p style="color: #CBD5E1; margin-bottom: 15px; font-size: 0.95rem;">
                        <strong>Purpose:</strong> Generate syntactically correct, optimized SQL from NL query.
                    </p>
                    <p style="color: #94A3B8; font-size: 0.9rem; margin-bottom: 10px;"><strong>Input:</strong> Clarified
                        query + Schema DDL</p>
                    <p style="color: #94A3B8; font-size: 0.9rem; margin-bottom: 10px;"><strong>Model:</strong> GPT-4o
                        (complex) / GPT-4o-mini (simple)</p>
                    <p style="color: #94A3B8; font-size: 0.9rem; margin-bottom: 10px;"><strong>Process:</strong></p>
                    <ol style="color: #CBD5E1; font-size: 0.9rem; padding-left: 20px; line-height: 1.7;">
                        <li>Analyze query complexity (joins, aggregations, subqueries)</li>
                        <li>Route to GPT-4o (complex) or GPT-4o-mini (simple)</li>
                        <li>Generate SQL with chain-of-thought reasoning</li>
                        <li>Self-validate: Check for syntax errors, security (no DROP/DELETE)</li>
                        <li>Returns: SQL query + explanation</li>
                    </ol>
                    <p style="color: #94A3B8; font-size: 0.9rem; margin-top: 10px;"><strong>Latency:</strong> ~1s (mini)
                        / ~1.5s (4o)</p>
                    <p style="color: #94A3B8; font-size: 0.9rem;"><strong>Cost:</strong> ‚Çπ1-4/query (model dependent)
                    </p>
                </div>

                <!-- Agent 4 -->
                <div class="agent-card">
                    <h4><span class="agent-icon">üìä</span> Agent 4: Formatter Agent</h4>
                    <p style="color: #CBD5E1; margin-bottom: 15px; font-size: 0.95rem;">
                        <strong>Purpose:</strong> Determine optimal output format (table/chart/summary).
                    </p>
                    <p style="color: #94A3B8; font-size: 0.9rem; margin-bottom: 10px;"><strong>Input:</strong> Original
                        query + SQL results metadata</p>
                    <p style="color: #94A3B8; font-size: 0.9rem; margin-bottom: 10px;"><strong>Model:</strong>
                        GPT-4o-mini</p>
                    <p style="color: #94A3B8; font-size: 0.9rem; margin-bottom: 10px;"><strong>Process:</strong></p>
                    <ol style="color: #CBD5E1; font-size: 0.9rem; padding-left: 20px; line-height: 1.7;">
                        <li>Analyze result structure (row count, column types)</li>
                        <li>Classify query intent (comparison, trend, lookup, aggregation)</li>
                        <li>Decide format: Table (raw data), Chart (time-series/comparison), Summary (single value)</li>
                        <li>For charts: Select type (line, bar, pie) and axes</li>
                        <li>Returns: Format spec + natural language summary</li>
                    </ol>
                    <p style="color: #94A3B8; font-size: 0.9rem; margin-top: 10px;"><strong>Latency:</strong> ~400ms</p>
                    <p style="color: #94A3B8; font-size: 0.9rem;"><strong>Cost:</strong> ~‚Çπ0.30/query</p>
                </div>
            </div>
        </div>

        <!-- LangGraph Workflow -->
        <div class="card">
            <h2>üîÑ LangGraph State Machine Workflow</h2>
            <p style="color: #CBD5E1; margin-bottom: 25px;">
                The following is the complete LangGraph workflow showing how agents collaborate:
            </p>

            <div class="workflow-step">
                <strong>Step 1: Initialize State</strong>
                <p style="color: #CBD5E1; font-size: 0.95rem;">
                    User query received ‚Üí Create state object with <code>query</code>, <code>schema</code>,
                    <code>sql</code>, <code>results</code>, <code>format</code> fields
                </p>
            </div>

            <div class="workflow-step">
                <strong>Step 2: Schema Retrieval (Agent 1)</strong>
                <p style="color: #CBD5E1; font-size: 0.95rem;">
                    State.query ‚Üí Agent 1 ‚Üí State.schema = [relevant tables DDL]<br>
                    <span style="color: #94A3B8; font-size: 0.85rem;">If no tables found: Return "Schema not found"
                        error, terminate</span>
                </p>
            </div>

            <div class="workflow-step">
                <strong>Step 3: Conditional: Ambiguity Check</strong>
                <p style="color: #CBD5E1; font-size: 0.95rem;">
                    LangGraph routes to Agent 2 if complexity score > threshold<br>
                    ‚Üí If ambiguous: Pause workflow, request user clarification (human-in-loop)<br>
                    ‚Üí If clear: Skip to Step 4
                </p>
            </div>

            <div class="workflow-step">
                <strong>Step 4: SQL Generation (Agent 3)</strong>
                <p style="color: #CBD5E1; font-size: 0.95rem;">
                    State.query + State.schema ‚Üí Agent 3 ‚Üí State.sql = "SELECT ..."<br>
                    <span style="color: #94A3B8; font-size: 0.85rem;">If validation fails: Retry with Claude 3.5 Sonnet
                        (fallback), max 2 retries</span>
                </p>
            </div>

            <div class="workflow-step">
                <strong>Step 5: Execute SQL (Non-Agent Service)</strong>
                <p style="color: #CBD5E1; font-size: 0.95rem;">
                    State.sql ‚Üí Database Gateway (Supabase/Customer DB) ‚Üí State.results = [rows]<br>
                    <span style="color: #94A3B8; font-size: 0.85rem;">Security: Read-only user, query timeout 30s, max
                        10K rows</span>
                </p>
            </div>

            <div class="workflow-step">
                <strong>Step 6: Format Decision (Agent 4)</strong>
                <p style="color: #CBD5E1; font-size: 0.95rem;">
                    State.query + State.results_metadata ‚Üí Agent 4 ‚Üí State.format = {type: "chart", chartType: "line",
                    ...}<br>
                    Returns to frontend with SQL, results, and format specification
                </p>
            </div>

            <div class="alert-box">
                <h4>üõ†Ô∏è LangGraph Implementation Code Snippet</h4>
                <pre
                    style="background: rgba(0,0,0,0.3); padding: 15px; border-radius: 8px; overflow-x: auto; color: #CBD5E1; font-size: 0.85rem;"><code>from langgraph.graph import StateGraph, END
from typing import TypedDict

class QueryState(TypedDict):
    query: str
    schema: list
    sql: str
    results: list
    format: dict

workflow = StateGraph(QueryState)

# Add nodes (agents)
workflow.add_node("schema_retriever", schema_agent)
workflow.add_node("clarification", clarification_agent)
workflow.add_node("sql_generator", sql_agent)
workflow.add_node("formatter", formatter_agent)

# Define edges (flow)
workflow.set_entry_point("schema_retriever")
workflow.add_conditional_edges(
    "schema_retriever",
    lambda state: "clarification" if needs_clarification(state) else "sql_generator"
)
workflow.add_edge("clarification", "sql_generator")
workflow.add_edge("sql_generator", "formatter")
workflow.add_edge("formatter", END)

app = workflow.compile()</code></pre>
            </div>
        </div>

        <!-- Deployment Strategy -->
        <div class="card">
            <h2>üöÄ AI Deployment Strategy</h2>

            <h3>Where to Deploy AI Components</h3>
            <table>
                <thead>
                    <tr>
                        <th>Component</th>
                        <th>Development</th>
                        <th>MVP/Production</th>
                        <th>Reason</th>
                    </tr>
                </thead>
                <tbody>
                    <tr>
                        <td><strong>LangGraph Orchestration</strong></td>
                        <td>Local Docker</td>
                        <td>AWS ECS Fargate (container)</td>
                        <td>Stateless, scales horizontally</td>
                    </tr>
                    <tr>
                        <td><strong>LLM Inference</strong></td>
                        <td>OpenAI API / Groq API</td>
                        <td>OpenAI API (primary)</td>
                        <td>No GPU management, pay-per-use</td>
                    </tr>
                    <tr>
                        <td><strong>Embedding Generation</strong></td>
                        <td>OpenAI API</td>
                        <td>OpenAI API</td>
                        <td>Cheap ($0.02/1M tokens)</td>
                    </tr>
                    <tr>
                        <td><strong>Vector Database</strong></td>
                        <td>LanceDB (embedded)</td>
                        <td>LanceDB Cloud / Pinecone</td>
                        <td>Managed, low latency semantic search</td>
                    </tr>
                    <tr>
                        <td><strong>Agent State Storage</strong></td>
                        <td>Redis (Docker)</td>
                        <td>ElastiCache Redis</td>
                        <td>Fast state persistence for LangGraph</td>
                    </tr>
                    <tr>
                        <td><strong>Monitoring (LangSmith)</strong></td>
                        <td>LangSmith Cloud</td>
                        <td>LangSmith Cloud</td>
                        <td>Native LangChain observability</td>
                    </tr>
                </tbody>
            </table>

            <div class="alert-box success">
                <h4>‚úÖ Recommended: 100% Cloud APIs (No Self-Hosting)</h4>
                <p style="color: #CBD5E1; line-height: 1.8;">
                    <strong>Why NOT self-host LLMs?</strong><br>
                    ‚Ä¢ GPU costs: AWS p3.2xlarge (V100) = ‚Çπ90,000/month vs API = ‚Çπ20,000/month<br>
                    ‚Ä¢ DevOps overhead: Model updates, serving infrastructure, scaling<br>
                    ‚Ä¢ API advantages: Instant access to GPT-4o, Claude 3.5, zero maintenance<br>
                    ‚Ä¢ Our usage (10K queries/month) is too low to justify self-hosting<br><br>

                    <strong>Break-even point:</strong> Self-hosting becomes cost-effective at ~500K+ queries/month
                </p>
            </div>
        </div>

        <!-- Cost Breakdown -->
        <div class="card">
            <h2>üí∞ Complete AI Cost Breakdown</h2>

            <h3>Monthly Costs (10K queries/month)</h3>
            <div class="model-comparison">
                <div class="cost-row">
                    <span class="cost-label">OpenAI GPT-4o-mini (7K queries)</span>
                    <span class="cost-value">‚Çπ3,500/mo</span>
                </div>
                <div class="cost-row">
                    <span class="cost-label">OpenAI GPT-4o (2.5K queries)</span>
                    <span class="cost-value">‚Çπ12,000/mo</span>
                </div>
                <div class="cost-row">
                    <span class="cost-label">Claude 3.5 Sonnet (500 fallback queries)</span>
                    <span class="cost-value">‚Çπ3,500/mo</span>
                </div>
                <div class="cost-row">
                    <span class="cost-label">OpenAI Embeddings (schema updates, 1M tokens/mo)</span>
                    <span class="cost-value">‚Çπ500/mo</span>
                </div>
                <div class="cost-row">
                    <span class="cost-label">LanceDB Cloud (Vector DB, 100K embeddings)</span>
                    <span class="cost-value">‚Çπ1,500/mo</span>
                </div>
                <div class="cost-row">
                    <span class="cost-label">LangSmith (Agent monitoring, 50K traces/mo)</span>
                    <span class="cost-value">$20 = ‚Çπ1,700/mo</span>
                </div>
                <div class="cost-row">
                    <span class="cost-label"><strong>TOTAL AI COST</strong></span>
                    <span class="cost-value" style="color: #fff;">‚Çπ22,700/mo = ‚Çπ2.72L/year</span>
                </div>
            </div>

            <h3 style="margin-top: 40px;">Cost Scaling (Growth Scenarios)</h3>
            <table>
                <thead>
                    <tr>
                        <th>Stage</th>
                        <th>Queries/Month</th>
                        <th>LLM API Cost</th>
                        <th>Infra Cost</th>
                        <th>Total AI Cost</th>
                    </tr>
                </thead>
                <tbody>
                    <tr>
                        <td><strong>MVP</strong></td>
                        <td>5,000</td>
                        <td>‚Çπ10,000</td>
                        <td>‚Çπ3,000</td>
                        <td>‚Çπ13,000/mo</td>
                    </tr>
                    <tr>
                        <td><strong>Early Growth</strong></td>
                        <td>10,000</td>
                        <td>‚Çπ19,500</td>
                        <td>‚Çπ3,700</td>
                        <td>‚Çπ23,200/mo</td>
                    </tr>
                    <tr>
                        <td><strong>Growth</strong></td>
                        <td>50,000</td>
                        <td>‚Çπ97,500</td>
                        <td>‚Çπ8,000</td>
                        <td>‚Çπ1.05L/mo</td>
                    </tr>
                    <tr>
                        <td><strong>Scale</strong></td>
                        <td>100,000</td>
                        <td>‚Çπ1.95L</td>
                        <td>‚Çπ15,000</td>
                        <td>‚Çπ2.1L/mo</td>
                    </tr>
                </tbody>
            </table>
        </div>

        <!-- Available Frameworks -->
        <div class="card">
            <h2>üõ†Ô∏è Available LangChain/LangGraph Components</h2>
            <p style="color: #CBD5E1; margin-bottom: 25px;">
                LangChain provides pre-built components that we leverage extensively:
            </p>

            <div class="grid-3">
                <div class="agent-card">
                    <h4>üì¶ SQL Agent (Pre-built)</h4>
                    <p style="color: #CBD5E1; font-size: 0.9rem;">
                        <code>langchain.agents.agent_toolkits.SQLDatabaseToolkit</code><br><br>
                        Provides: Schema inspection, SQL execution, error correction<br><br>
                        <strong>Status:</strong> We extend this with custom validation and security checks
                    </p>
                </div>

                <div class="agent-card">
                    <h4>üîç Retrieval Chain (Pre-built)</h4>
                    <p style="color: #CBD5E1; font-size: 0.9rem;">
                        <code>langchain.chains.RetrievalQA</code><br><br>
                        Provides: Vector search, context retrieval, RAG pattern<br><br>
                        <strong>Status:</strong> Used for schema retrieval with LanceDB integration
                    </p>
                </div>

                <div class="agent-card">
                    <h4>ü§ñ OpenAI Functions (Pre-built)</h4>
                    <p style="color: #CBD5E1; font-size: 0.9rem;">
                        <code>langchain.chat_models.ChatOpenAI</code> with function calling<br><br>
                        Provides: Structured output, tool selection<br><br>
                        <strong>Status:</strong> Used for formatter agent to return JSON format specs
                    </p>
                </div>
            </div>

            <div class="alert-box">
                <h4>üèóÔ∏è Custom vs Pre-built Breakdown</h4>
                <p style="color: #CBD5E1; line-height: 1.8;">
                    <strong>Using LangChain Pre-built (40%):</strong><br>
                    ‚Ä¢ SQL Database Toolkit for schema inspection<br>
                    ‚Ä¢ RetrievalQA chain for semantic schema search<br>
                    ‚Ä¢ OpenAI function calling for structured outputs<br>
                    ‚Ä¢ LangSmith for observability<br><br>

                    <strong>Custom Implementation (60%):</strong><br>
                    ‚Ä¢ Clarification agent (ambiguity detection logic)<br>
                    ‚Ä¢ Model routing strategy (GPT-4o vs mini)<br>
                    ‚Ä¢ SQL validation and security checks (no DELETE/DROP)<br>
                    ‚Ä¢ Query complexity classifier<br>
                    ‚Ä¢ Format decision tree (table vs chart vs summary)
                </p>
            </div>
        </div>

        <!-- Performance & Optimization -->
        <div class="card">
            <h2>‚ö° Performance Optimization Strategies</h2>

            <div class="grid-3">
                <div class="agent-card">
                    <h4>üóÑÔ∏è Schema Caching</h4>
                    <p style="color: #CBD5E1; font-size: 0.9rem;">
                        ‚Ä¢ Cache full DB schemas in Redis (24hr TTL)<br>
                        ‚Ä¢ Generate embeddings once, store in LanceDB<br>
                        ‚Ä¢ Reduces 2s schema fetch to 50ms cache hit<br>
                        ‚Ä¢ Saves ~‚Çπ5,000/month in LLM calls
                    </p>
                </div>

                <div class="agent-card">
                    <h4>üéØ Prompt Optimization</h4>
                    <p style="color: #CBD5E1; font-size: 0.9rem;">
                        ‚Ä¢ Few-shot examples in system prompt<br>
                        ‚Ä¢ Chain-of-thought for complex queries<br>
                        ‚Ä¢ Token reduction: 800 ‚Üí 400 avg tokens<br>
                        ‚Ä¢ 50% cost savings on LLM API calls
                    </p>
                </div>

                <div class="agent-card">
                    <h4>üîÑ Batch Processing</h4>
                    <p style="color: #CBD5E1; font-size: 0.9rem;">
                        ‚Ä¢ Batch schema embedding generation<br>
                        ‚Ä¢ Async agent calls (non-blocking)<br>
                        ‚Ä¢ Parallel SQL validation checks<br>
                        ‚Ä¢ Reduces end-to-end latency by 40%
                    </p>
                </div>
            </div>
        </div>

        <!-- Risk Mitigation -->
        <div class="card">
            <h2>‚ö†Ô∏è Risk Mitigation & Fallback Strategies</h2>

            <table>
                <thead>
                    <tr>
                        <th>Risk</th>
                        <th>Impact</th>
                        <th>Mitigation</th>
                        <th>Fallback</th>
                    </tr>
                </thead>
                <tbody>
                    <tr>
                        <td><strong>OpenAI API Outage</strong></td>
                        <td>Service down</td>
                        <td>Multi-provider strategy</td>
                        <td>Auto-failover to Claude 3.5 Sonnet (Anthropic)</td>
                    </tr>
                    <tr>
                        <td><strong>Hallucinated SQL</strong></td>
                        <td>Wrong results</td>
                        <td>SQL validation + dry-run EXPLAIN</td>
                        <td>Show SQL to user for manual review</td>
                    </tr>
                    <tr>
                        <td><strong>Cost Spike</strong></td>
                        <td>Budget overrun</td>
                        <td>Per-user rate limits (100 queries/day)</td>
                        <td>Queue overflow queries, notify admin</td>
                    </tr>
                    <tr>
                        <td><strong>LLM Latency > 5s</strong></td>
                        <td>Poor UX</td>
                        <td>Timeout after 10s, retry with faster model</td>
                        <td>GPT-4o ‚Üí GPT-4o-mini fallback</td>
                    </tr>
                    <tr>
                        <td><strong>Schema Drift</strong></td>
                        <td>Stale metadata</td>
                        <td>Daily schema sync + invalidate cache on DDL</td>
                        <td>Manual "Refresh Schema" button for users</td>
                    </tr>
                </tbody>
            </table>
        </div>

        <!-- Stakeholder Summary -->
        <div class="card">
            <h2>üìä Stakeholder Summary: Why This Architecture?</h2>

            <div class="alert-box success">
                <h4>‚úÖ For Investors</h4>
                <p style="color: #CBD5E1; line-height: 1.8;">
                    ‚Ä¢ <strong>Capital Efficient:</strong> ‚Çπ2.7L/year AI cost vs ‚Çπ50L+ if self-hosting GPUs<br>
                    ‚Ä¢ <strong>Time to Market:</strong> Leverage OpenAI/Anthropic APIs, no 6-month model training<br>
                    ‚Ä¢ <strong>Scalable:</strong> Pay-per-use model, costs scale linearly with revenue<br>
                    ‚Ä¢ <strong>Competitive Moat:</strong> Multi-agent accuracy (95%+) beats single-LLM competitors (80%)
                </p>
            </div>

            <div class="alert-box">
                <h4>üîß For Engineering Team</h4>
                <p style="color: #CBD5E1; line-height: 1.8;">
                    ‚Ä¢ <strong>Modern Stack:</strong> LangGraph (state-of-the-art agent framework)<br>
                    ‚Ä¢ <strong>Observable:</strong> LangSmith traces every agent decision<br>
                    ‚Ä¢ <strong>Maintainable:</strong> 60% LangChain pre-built, 40% custom logic<br>
                    ‚Ä¢ <strong>Testable:</strong> Each agent has unit tests + E2E query test suite<br>
                    ‚Ä¢ <strong>Extensible:</strong> Add new agents (e.g., Chart Generator) without rewrite
                </p>
            </div>

            <div class="alert-box">
                <h4>üéØ For AI Experts/Advisors</h4>
                <p style="color: #CBD5E1; line-height: 1.8;">
                    ‚Ä¢ <strong>Proven Pattern:</strong> ReAct-style agent orchestration (LangGraph)<br>
                    ‚Ä¢ <strong>Model Selection:</strong> Hybrid routing (GPT-4o + mini) optimizes cost/accuracy
                    tradeoff<br>
                    ‚Ä¢ <strong>Error Handling:</strong> Validation, retries, fallback models<br>
                    ‚Ä¢ <strong>Security:</strong> SQL injection prevention, read-only DB users, query whitelisting<br>
                    ‚Ä¢ <strong>Benchmarking:</strong> Spider benchmark + custom NL-to-SQL test suite (500 queries)<br>
                    ‚Ä¢ <strong>Future-Proof:</strong> Easy to swap GPT-5, Llama 4 when released
                </p>
            </div>
        </div>

    </div>

</body>

</html>
